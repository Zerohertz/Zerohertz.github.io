<!DOCTYPE html>
<html lang="en">
<head>
  <meta property="og:image" content="https://user-images.githubusercontent.com/42334717/89857466-2301e600-dbd7-11ea-9f52-f375b8a3d435.jpg">
  <script type="text/javascript" src="//wcs.naver.net/wcslog.js"></script>
  <script type="text/javascript">
  if(!wcs_add) var wcs_add = {};
  wcs_add["wa"] = "7e701a42aec008";
  if(window.wcs) {
      wcs_do();
  }
  </script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#800a0a">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="https://user-images.githubusercontent.com/42334717/60787577-38ffd480-a195-11e9-83a7-25af69eda64a.png">
  <link rel="icon" type="image/png" sizes="32x32" href="https://user-images.githubusercontent.com/42334717/60787577-38ffd480-a195-11e9-83a7-25af69eda64a.png">
  <link rel="icon" type="image/png" sizes="16x16" href="https://user-images.githubusercontent.com/42334717/60787577-38ffd480-a195-11e9-83a7-25af69eda64a.png">
  <link rel="mask-icon" href="https://user-images.githubusercontent.com/42334717/60787577-38ffd480-a195-11e9-83a7-25af69eda64a.png" color="#800a0a">
  <link rel="manifest" href="https://user-images.githubusercontent.com/42334717/60787577-38ffd480-a195-11e9-83a7-25af69eda64a.png">
  <meta name="msapplication-config" content="https://user-images.githubusercontent.com/42334717/60787577-38ffd480-a195-11e9-83a7-25af69eda64a.png">
  <meta name="google-site-verification" content="PYYAJFWpEyGVVDYPD7Cmj5hll1zjjqk8PjonhYX3VjE">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zerohertz.github.io","root":"/","scheme":"Pisces","version":"8.0.0","exturl":true,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#800a0a","save":false},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"disqus","storage":true,"lazyload":false,"nav":null,"activeClass":"disqus"},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeInDown","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInDown","sidebar":"fadeInDown"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="IntroductionWhy Data Mining? 데이터가 풍부하지만 정보가 열악한 상황 - 강력한 데이터 분석 도구 필요   Repository에 수집 및 저장되는 크고 많은 데이터 빠르게 성장하는 빅데이터는 강력한 도구 없이는 이해할 수 없음 결과적으로 빅데이터 Repository에서 수집된 데이터는 거의 방문하지 않는 데이터 Archive인 데이터">
<meta property="og:type" content="article">
<meta property="og:title" content="Data Mining">
<meta property="og:url" content="https://zerohertz.github.io/data-mining/index.html">
<meta property="og:site_name" content="Zerohertz">
<meta property="og:description" content="IntroductionWhy Data Mining? 데이터가 풍부하지만 정보가 열악한 상황 - 강력한 데이터 분석 도구 필요   Repository에 수집 및 저장되는 크고 많은 데이터 빠르게 성장하는 빅데이터는 강력한 도구 없이는 이해할 수 없음 결과적으로 빅데이터 Repository에서 수집된 데이터는 거의 방문하지 않는 데이터 Archive인 데이터">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://user-images.githubusercontent.com/42334717/74623830-798eea00-5189-11ea-9b92-2a254b4bbb79.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/42334717/74625699-8d8a1a00-5190-11ea-8bd3-2b3e2b76f36b.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/42334717/74628030-dc877d80-5197-11ea-8101-600f431aca58.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/42334717/74633998-532b7780-51a6-11ea-859a-33193cf8f4f0.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/42334717/74634132-9ede2100-51a6-11ea-8a94-2887f8e3d463.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/42334717/74634337-fa101380-51a6-11ea-8ba2-13030ecf6be7.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/42334717/74701775-3a28d200-524b-11ea-8608-41c177e88e74.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/42334717/74702739-39de0600-524e-11ea-96a9-7d57e679845a.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/42334717/89777041-f487fa80-db45-11ea-9dc4-f9a644fb68b9.png">
<meta property="article:published_time" content="2020-02-06T05:24:06.000Z">
<meta property="article:modified_time" content="2020-08-26T08:06:35.145Z">
<meta property="article:author" content="Zerohertz">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Signal Processing">
<meta property="article:tag" content="DNN">
<meta property="article:tag" content="Statistics">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://user-images.githubusercontent.com/42334717/74623830-798eea00-5189-11ea-9b92-2a254b4bbb79.png">


<link rel="canonical" href="https://zerohertz.github.io/data-mining/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Data Mining | Zerohertz</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-145420109-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-145420109-1');
      }
    </script>






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

<link rel="alternate" href="/rss2.xml" title="Zerohertz" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zerohertz</h1>
      <i class="logo-line"></i>
    </a>
      <img class="custom-logo-image" src="https://user-images.githubusercontent.com/42334717/76139363-5c678000-6092-11ea-9c6c-585be21a64cd.png" alt="Zerohertz">
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">25</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">19</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">102</span></a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="Searching..." spellcheck="false" type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Why-Data-Mining"><span class="nav-number">1.1.</span> <span class="nav-text">Why Data Mining?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Mining"><span class="nav-number">1.2.</span> <span class="nav-text">Data Mining?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#What-kinds-of-Data-Can-Be-Mined"><span class="nav-number">1.3.</span> <span class="nav-text">What kinds of Data Can Be Mined?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#What-kinds-of-Patterns-Can-Be-Mined"><span class="nav-number">1.4.</span> <span class="nav-text">What kinds of Patterns Can Be Mined?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Analysis-of-Data"><span class="nav-number">1.5.</span> <span class="nav-text">Analysis of Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Classification"><span class="nav-number">1.5.1.</span> <span class="nav-text">Classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cluster-Analysis"><span class="nav-number">1.5.2.</span> <span class="nav-text">Cluster Analysis</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Outlier-Analysis"><span class="nav-number">1.5.3.</span> <span class="nav-text">Outlier Analysis</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Getting-to-Know-Your-Data"><span class="nav-number">2.</span> <span class="nav-text">Getting to Know Your Data</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-objects-and-Attribute-Types"><span class="nav-number">2.1.</span> <span class="nav-text">Data objects and Attribute Types</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-Is-an-Attribute"><span class="nav-number">2.1.1.</span> <span class="nav-text">What Is an Attribute?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Discrete-versus-Continuous-Attributes"><span class="nav-number">2.1.2.</span> <span class="nav-text">Discrete versus Continuous Attributes</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-Statistical-Descriptions-of-Data"><span class="nav-number">2.2.</span> <span class="nav-text">Basic Statistical Descriptions of Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Measuring-the-Central-Tendency-Mean-Median-and-Mode"><span class="nav-number">2.2.1.</span> <span class="nav-text">Measuring the Central Tendency : Mean, Median, and Mode</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Measuring-the-Dispersion-of-Data-Range-Quartiles-Variance-Standard-Deviation-and-Interquartile-Range"><span class="nav-number">2.2.2.</span> <span class="nav-text">Measuring the Dispersion of Data : Range, Quartiles, Variance, Standard Deviation, and Interquartile Range</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Range-Quartiles-and-Interquartile-Range"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">Range, Quartiles, and Interquartile Range</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Five-Number-Summary-Boxplots-and-Outliers"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">Five-Number Summary, Boxplots, and Outliers</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Variance-and-Standard-Deviation"><span class="nav-number">2.2.2.3.</span> <span class="nav-text">Variance and Standard Deviation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Graphic-Displays-of-Basic-Statistical-Descriptions-of-Data"><span class="nav-number">2.2.3.</span> <span class="nav-text">Graphic Displays of Basic Statistical Descriptions of Data</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Visualization"><span class="nav-number">2.3.</span> <span class="nav-text">Data Visualization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pixel-Oriented-Visualization-Techniques"><span class="nav-number">2.3.1.</span> <span class="nav-text">Pixel-Oriented Visualization Techniques</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Geometric-Projection-Visualization-Techniques"><span class="nav-number">2.3.2.</span> <span class="nav-text">Geometric Projection Visualization Techniques</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Icon-Based-Visualization-Techniques"><span class="nav-number">2.3.3.</span> <span class="nav-text">Icon-Based Visualization Techniques</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hierarchical-Visualization-Techniques"><span class="nav-number">2.3.4.</span> <span class="nav-text">Hierarchical Visualization Techniques</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Measuring-Data-Similarity-and-Dissimilarity"><span class="nav-number">2.4.</span> <span class="nav-text">Measuring Data Similarity and Dissimilarity</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Matrix-versus-Dissimilarity-Matrix"><span class="nav-number">2.4.1.</span> <span class="nav-text">Data Matrix versus Dissimilarity Matrix</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Proximity-Measures-for-Nominal-Attribute"><span class="nav-number">2.4.2.</span> <span class="nav-text">Proximity Measures for Nominal Attribute</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Proximity-Measures-for-Binary-Attributes"><span class="nav-number">2.4.3.</span> <span class="nav-text">Proximity Measures for Binary Attributes</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dissimilarity-of-Numeric-Data-Minkowski-Distance"><span class="nav-number">2.4.4.</span> <span class="nav-text">Dissimilarity of Numeric Data : Minkowski Distance</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Proximity-Measures-for-Ordinal-Attributes"><span class="nav-number">2.4.5.</span> <span class="nav-text">Proximity Measures for Ordinal Attributes</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dissimilarity-for-Attributes-of-Mixed-Types"><span class="nav-number">2.4.6.</span> <span class="nav-text">Dissimilarity for Attributes of Mixed Types</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cosine-Similarity"><span class="nav-number">2.4.7.</span> <span class="nav-text">Cosine Similarity</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Data-Preprocessing"><span class="nav-number">3.</span> <span class="nav-text">Data Preprocessing</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Cleaning"><span class="nav-number">3.1.</span> <span class="nav-text">Data Cleaning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Missing-Values"><span class="nav-number">3.1.1.</span> <span class="nav-text">Missing Values</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Noisy-Data"><span class="nav-number">3.1.2.</span> <span class="nav-text">Noisy Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Cleaning-as-a-Process"><span class="nav-number">3.1.3.</span> <span class="nav-text">Data Cleaning as a Process</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Integration"><span class="nav-number">3.2.</span> <span class="nav-text">Data Integration</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Redundancy-and-Correlation-Analysis"><span class="nav-number">3.2.1.</span> <span class="nav-text">Redundancy and Correlation Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#chi-2-Correlation-Test-for-Nominal-Data"><span class="nav-number">3.2.1.1.</span> <span class="nav-text">$\chi^2$ Correlation Test for Nominal Data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Correlation-Coefficient-for-Numeric-Data"><span class="nav-number">3.2.1.2.</span> <span class="nav-text">Correlation Coefficient for Numeric Data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Covariance-of-Numeric-Data"><span class="nav-number">3.2.1.3.</span> <span class="nav-text">Covariance of Numeric Data</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tuple-Duplication"><span class="nav-number">3.2.2.</span> <span class="nav-text">Tuple Duplication</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Value-Conflict-Detection-and-Resolution"><span class="nav-number">3.2.3.</span> <span class="nav-text">Data Value Conflict Detection and Resolution</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Reduction"><span class="nav-number">3.3.</span> <span class="nav-text">Data Reduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Overview-of-Data-Reduction-Strategies"><span class="nav-number">3.3.1.</span> <span class="nav-text">Overview of Data Reduction Strategies</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Wavelet-Transform"><span class="nav-number">3.3.2.</span> <span class="nav-text">Wavelet Transform</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Principal-Components-Analysis-PCA"><span class="nav-number">3.3.3.</span> <span class="nav-text">Principal Components Analysis(PCA)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Attribute-Subset-Selection"><span class="nav-number">3.3.4.</span> <span class="nav-text">Attribute Subset Selection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Regression-and-Log-Linear-Models-Parametric-Data-Reduction"><span class="nav-number">3.3.5.</span> <span class="nav-text">Regression and Log-Linear Models : Parametric Data Reduction</span></a></li></ol></li></ol></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zerohertz" src="https://user-images.githubusercontent.com/42334717/71893479-250e4d00-318f-11ea-8989-0226312ff0f1.jpeg">
  <p class="site-author-name" itemprop="name">Zerohertz</p>
  <div class="site-description" itemprop="description">#800a0a</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">102</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1plcm9oZXJ0eg==" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Zerohertz"><i class="fab fa-github fa-fw"></i></span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOm9oZzM0MTdAZ21haWwuY29t" title="E-Mail → mailto:ohg3417@gmail.com"><i class="fa fa-envelope fa-fw"></i></span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly93d3cuZmFjZWJvb2suY29tL3Blb3BsZS8lRUMlOTglQTQlRUQlOUElQTglRUElQjclQkMvMTAwMDEzOTQyMDg2NTY3" title="FB Page → https:&#x2F;&#x2F;www.facebook.com&#x2F;people&#x2F;%EC%98%A4%ED%9A%A8%EA%B7%BC&#x2F;100013942086567"><i class="fab fa-facebook fa-fw"></i></span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly93d3cuaW5zdGFncmFtLmNvbS96ZXJvaGVydHp6Lw==" title="Instagram → https:&#x2F;&#x2F;www.instagram.com&#x2F;zerohertzz&#x2F;"><i class="fab fa-instagram fa-fw"></i></span>
      </span>
  </div>



      </section>
        <div class="back-to-top animated">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zerohertz.github.io/data-mining/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://user-images.githubusercontent.com/42334717/71893479-250e4d00-318f-11ea-8989-0226312ff0f1.jpeg">
      <meta itemprop="name" content="Zerohertz">
      <meta itemprop="description" content="#800a0a">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zerohertz">
    </span>

    
    
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Data Mining
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-02-06 14:24:06" itemprop="dateCreated datePublished" datetime="2020-02-06T14:24:06+09:00">2020-02-06</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-08-26 17:06:35" itemprop="dateModified" datetime="2020-08-26T17:06:35+09:00">2020-08-26</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/book/" itemprop="url" rel="index"><span itemprop="name">Book</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/book/data-mining/" itemprop="url" rel="index"><span itemprop="name">Data Mining</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/data-mining/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="data-mining/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>17k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>16 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Why-Data-Mining"><a href="#Why-Data-Mining" class="headerlink" title="Why Data Mining?"></a>Why Data Mining?</h2><blockquote>
<p>데이터가 풍부하지만 정보가 열악한 상황 - 강력한 데이터 분석 도구 필요</p>
</blockquote>
<ul>
<li>Repository에 수집 및 저장되는 크고 많은 데이터 빠르게 성장하는 빅데이터는 강력한 도구 없이는 이해할 수 없음</li>
<li>결과적으로 빅데이터 Repository에서 수집된 데이터는 거의 방문하지 않는 데이터 Archive인 데이터 무덤이 됨</li>
<li>의사 결정자에게 방대한 양의 데이터에 포함된 지식 추출 도구가 없기 때문에 데이터 Repository에 저장된 정보가 풍부한 데이터가 아니라 의사 결정자의 직감에 따라 중요한 의사결정이 종종 이루어짐</li>
<li>이를 위해 수동 지식 입력을 해야하지만 편견과 오류가 발생하기 쉽고 비용이 많이 들며 시간이 많이 걸림</li>
<li><strong>그러므로 데이터 마이닝 도구를 체계적으로 개발해야함</strong></li>
</ul>
<h2 id="Data-Mining"><a href="#Data-Mining" class="headerlink" title="Data Mining?"></a>Data Mining?</h2><blockquote>
<p>데이터를 통해 지식을 캐냄</p>
</blockquote>
<ol>
<li>Data cleaning(노이즈 및 일관되지 않은 데이터 제거)</li>
<li>Data integration(여러 데이터 소스를 결합할 수 있는 경우)</li>
<li>Data selection(분석 작업과 관련된 데이터를 데이터 베이스에서 검색)</li>
<li>Data transformation(요약 또는 집계 후 데이터 마이닝에 적합한 형태로 변환 및 통합되는 경우)</li>
<li><strong>Data mining</strong>(데이터 패턴 추출에 지능적인 방법을 적용하는 필수 프로세스)</li>
<li>Pattern evaluation(측정에 기초하여 지식을 나타내는 패턴 식별)</li>
<li>Knowledge presentation(시각화 및 지식 표현 기술을 사용하여 사용자에게 채굴한 지식을 제시)</li>
</ol>
<h2 id="What-kinds-of-Data-Can-Be-Mined"><a href="#What-kinds-of-Data-Can-Be-Mined" class="headerlink" title="What kinds of Data Can Be Mined?"></a>What kinds of Data Can Be Mined?</h2><ul>
<li>Database data<ul>
<li>Database management system(DBMS)라고도 불림</li>
<li>상호 관련된 데이터 모음</li>
<li>Relational database<ul>
<li>Attributes(Columns or Fields)</li>
<li>Tuples(Records or Rows)</li>
<li>Database queries를 통하여 접근할 수 있음</li>
</ul>
</li>
</ul>
</li>
<li>Data warehouse<ul>
<li>여러 소스에서 수집되어 통합 스키마로 저장</li>
<li>일반적으로 단일 사이트에있는 정보의 저장소</li>
<li>Data cleaning, Data integration, Data transformation, Data loading, Periodic data refreshing을 통하여 구성</li>
<li>다차원적인 데이터 구조인 Data cube를 통하여 모델링됨<ul>
<li>각 차원은 스키마의 Attribute 또는 Attribute의 집합에 해당</li>
<li>각 셀은 집계 측정 값을 저장</li>
</ul>
</li>
</ul>
</li>
<li>Other Kinds of Data<ul>
<li>Transactional data</li>
<li>Time-related or sequence data</li>
<li>Data streams</li>
<li>Spatial data</li>
<li>Engineering design data</li>
<li>Hypertext and multimedia data</li>
<li>Graph and networked data</li>
<li>Web</li>
</ul>
</li>
</ul>
<a id="more"></a>

<h2 id="What-kinds-of-Patterns-Can-Be-Mined"><a href="#What-kinds-of-Patterns-Can-Be-Mined" class="headerlink" title="What kinds of Patterns Can Be Mined?"></a>What kinds of Patterns Can Be Mined?</h2><ul>
<li>Class/Concept Description<ul>
<li>Data characterization : A Summarization of the general characteristics or features of a target class of data</li>
<li>Data discrimination : A comparison of the general features of the target class data objects against the general features of objects from one or multiple contrasting classes</li>
</ul>
</li>
<li>Mining Frequent Patterns, Associations, and Correlations<ul>
<li>Association analysis</li>
</ul>
</li>
</ul>
<h2 id="Analysis-of-Data"><a href="#Analysis-of-Data" class="headerlink" title="Analysis of Data"></a>Analysis of Data</h2><h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><blockquote>
<p>The process of finding a model(or function) that describes and distinguishes data classes or concepts</p>
</blockquote>
<ul>
<li>모델은 훈련 데이터의 분석을 기반하여 파생</li>
<li>모델은 Data를 Class label로 식별</li>
<li>Example<ul>
<li>Decision tree</li>
<li>Neural network</li>
</ul>
</li>
<li>Regression<ul>
<li>연속값 함수를 모델링</li>
<li>누락되거나 사용할 수 없는 데이터 예측</li>
</ul>
</li>
</ul>
<h3 id="Cluster-Analysis"><a href="#Cluster-Analysis" class="headerlink" title="Cluster Analysis"></a>Cluster Analysis</h3><blockquote>
<p>Clustering analyzes data objects without consulting class labels</p>
</blockquote>
<h3 id="Outlier-Analysis"><a href="#Outlier-Analysis" class="headerlink" title="Outlier Analysis"></a>Outlier Analysis</h3><blockquote>
<p>Outliers may be detected using statiscal tests that assume a distribution or probability model for the data, or using distance measures where objects that are remote from any other clustrerare considered outliers</p>
</blockquote>
<hr>
<h1 id="Getting-to-Know-Your-Data"><a href="#Getting-to-Know-Your-Data" class="headerlink" title="Getting to Know Your Data"></a>Getting to Know Your Data</h1><h2 id="Data-objects-and-Attribute-Types"><a href="#Data-objects-and-Attribute-Types" class="headerlink" title="Data objects and Attribute Types"></a>Data objects and Attribute Types</h2><ul>
<li>Data object : Representing an entity, The row of a database</li>
<li>Data tuple : If the data objects are stored in a database</li>
<li>Attribute : The columns of a database</li>
</ul>
<h3 id="What-Is-an-Attribute"><a href="#What-Is-an-Attribute" class="headerlink" title="What Is an Attribute?"></a>What Is an Attribute?</h3><blockquote>
<p>An attribute is a data field, representing a characteristic or feature of a data object</p>
</blockquote>
<ul>
<li>Nominal(명사의) Attributes : The values of a nominal attribute are symbols or names of things</li>
<li>Binary Attributes : A binary attribute is a nominal attribute with only two categories or states : 0 or 1, where 0 typically means that the attribute is absent, and 1 means that it is present</li>
<li>Ordinal(서수) Attributes : An ordinal attribute is an attribute with possible with possible values that have a meaningful order or ranking among them, but the magnitude between successive values is not known</li>
<li>Numeric Attributes : A numeric attribute is quantitative</li>
</ul>
<h3 id="Discrete-versus-Continuous-Attributes"><a href="#Discrete-versus-Continuous-Attributes" class="headerlink" title="Discrete versus Continuous Attributes"></a>Discrete versus Continuous Attributes</h3><ul>
<li>A discrete attribute has a finite or countably infinite set of values, which may or may not be represented as integers</li>
<li>If an attribute is not discrete, it is continuous</li>
</ul>
<h2 id="Basic-Statistical-Descriptions-of-Data"><a href="#Basic-Statistical-Descriptions-of-Data" class="headerlink" title="Basic Statistical Descriptions of Data"></a>Basic Statistical Descriptions of Data</h2><h3 id="Measuring-the-Central-Tendency-Mean-Median-and-Mode"><a href="#Measuring-the-Central-Tendency-Mean-Median-and-Mode" class="headerlink" title="Measuring the Central Tendency : Mean, Median, and Mode"></a>Measuring the Central Tendency : Mean, Median, and Mode</h3><ul>
<li><p>Mean<br>$$\bar x = \frac{\sum_{i=1}^{N} x_i}{N}=\frac{x_1+x_2+…+x_N}{N}$$</p>
</li>
<li><p>Weighted arithmetic mean / Weighted average<br>$$\bar x=\frac{\sum_{i=1}^{N}w_ix_i}{\sum_{i=1}^{N}w_i}=\frac{w_1x_1+w_2x_2+…+w_Nx_N}{w_1+w_2+…+w_N}$$</p>
</li>
<li><p>Median</p>
<ul>
<li>$L_1$ : The lower boundary of the median interval</li>
<li>$N$ : The number of values in the entire data set</li>
<li>$(\sum freq)_l$ : The sum of the frequencies of all the intervals that are lower than the median interval</li>
<li>$freq_{median}$ : The frequency of the median interval</li>
<li>$width$ : The width of the median interval</li>
</ul>
</li>
</ul>
<p>$$median=L_1+(\frac{N/2-(\sum freq)}{freq_{median}})width$$</p>
<ul>
<li>Mode : A set of data is the value that occurs most frequently in the set<ul>
<li>Unimodal</li>
<li>Bimodal</li>
<li>Trimodal</li>
<li>Multimodal</li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/42334717/74623830-798eea00-5189-11ea-9b92-2a254b4bbb79.png" alt="Skewness"></p>
<h3 id="Measuring-the-Dispersion-of-Data-Range-Quartiles-Variance-Standard-Deviation-and-Interquartile-Range"><a href="#Measuring-the-Dispersion-of-Data-Range-Quartiles-Variance-Standard-Deviation-and-Interquartile-Range" class="headerlink" title="Measuring the Dispersion of Data : Range, Quartiles, Variance, Standard Deviation, and Interquartile Range"></a>Measuring the Dispersion of Data : Range, Quartiles, Variance, Standard Deviation, and Interquartile Range</h3><h4 id="Range-Quartiles-and-Interquartile-Range"><a href="#Range-Quartiles-and-Interquartile-Range" class="headerlink" title="Range, Quartiles, and Interquartile Range"></a>Range, Quartiles, and Interquartile Range</h4><ul>
<li>Range<ul>
<li>The difference between the largest(<code>max()</code>) and smallest(<code>min()</code>) values</li>
</ul>
</li>
<li>Quartiles<ul>
<li>Points taken at regular intervals of a data distribution, dividing it into essentially equal size consecutive sets</li>
</ul>
</li>
<li>Percentiles<ul>
<li>The 100-quartiles</li>
</ul>
</li>
<li>First quartile<ul>
<li>$Q_1$, 25th percentile</li>
</ul>
</li>
<li>Third quartile<ul>
<li>$Q_3$, 75th percentile</li>
</ul>
</li>
<li>Interquartile range(IQR)<ul>
<li>$IQR=Q_3-Q_1$</li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/42334717/74625699-8d8a1a00-5190-11ea-8bd3-2b3e2b76f36b.png" alt="Percentile"></p>
<h4 id="Five-Number-Summary-Boxplots-and-Outliers"><a href="#Five-Number-Summary-Boxplots-and-Outliers" class="headerlink" title="Five-Number Summary, Boxplots, and Outliers"></a>Five-Number Summary, Boxplots, and Outliers</h4><ul>
<li>Five-Number Summary<ul>
<li>Minimum</li>
<li>$Q_1$</li>
<li>Median($Q_2$)</li>
<li>$Q_3$</li>
<li>Maximum</li>
</ul>
</li>
</ul>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; summary(Cars93$Price)</span><br><span class="line">   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span><br><span class="line">   <span class="number">7.40</span>   <span class="number">12.20</span>   <span class="number">17.70</span>   <span class="number">19.51</span>   <span class="number">23.30</span>   <span class="number">61.90</span> </span><br></pre></td></tr></table></figure>

<ul>
<li>Boxplots<ul>
<li>Typically, the ends of the box quartiles so that the box length is the interquartile range(IQR)</li>
<li>The median is marked by a line within the box</li>
<li>Two lines(called whiskers) outside the box extend to the smallest(Minimum) and largest(Maximum) observations</li>
</ul>
</li>
</ul>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; boxplot(Cars93$Price)</span><br></pre></td></tr></table></figure>

<img width="1145" alt="Boxplot" src="https://user-images.githubusercontent.com/42334717/74628030-dc877d80-5197-11ea-8101-600f431aca58.png">

<h4 id="Variance-and-Standard-Deviation"><a href="#Variance-and-Standard-Deviation" class="headerlink" title="Variance and Standard Deviation"></a>Variance and Standard Deviation</h4><ul>
<li><p>Variance<br>$$\sigma^2=\frac{1}{N}\sum_{i=1}^{N}(x_i-\bar x)^2=(\frac{1}{N}\sum_{i=1}^{N}x_i^2)-\bar x^2$$</p>
</li>
<li><p>Standard deviation<br>$$\sigma$$</p>
</li>
</ul>
<h3 id="Graphic-Displays-of-Basic-Statistical-Descriptions-of-Data"><a href="#Graphic-Displays-of-Basic-Statistical-Descriptions-of-Data" class="headerlink" title="Graphic Displays of Basic Statistical Descriptions of Data"></a>Graphic Displays of Basic Statistical Descriptions of Data</h3><ul>
<li>Quantile Plot</li>
<li>Quantile-Quantile Plot(q-q plot)</li>
<li>Histograms(frequency histograms)</li>
<li>Scatter Plots</li>
<li>Data Correlation</li>
</ul>
<h2 id="Data-Visualization"><a href="#Data-Visualization" class="headerlink" title="Data Visualization"></a>Data Visualization</h2><blockquote>
<p>Data visualization aims to communicate data clearly and effectively through graphical representation</p>
</blockquote>
<h3 id="Pixel-Oriented-Visualization-Techniques"><a href="#Pixel-Oriented-Visualization-Techniques" class="headerlink" title="Pixel-Oriented Visualization Techniques"></a>Pixel-Oriented Visualization Techniques</h3><ul>
<li>For a data set of m dimensions, pixel-oriented techniques create m windows on the screen, one for each dimension</li>
<li>The m dimension values of a record are mapped to m pixels at the corresponding positions in the windows</li>
<li>The colors of the pixels reflect the corresponding values</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/42334717/74633998-532b7780-51a6-11ea-859a-33193cf8f4f0.png" alt="Pixel-Oriented Visualization Techniques"></p>
<h3 id="Geometric-Projection-Visualization-Techniques"><a href="#Geometric-Projection-Visualization-Techniques" class="headerlink" title="Geometric Projection Visualization Techniques"></a>Geometric Projection Visualization Techniques</h3><blockquote>
<p>Geometric projection techniques help users find interesting projections of multidimensional data sets</p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/42334717/74634132-9ede2100-51a6-11ea-8a94-2887f8e3d463.png" alt="Geometric Projection Visualization Techniques"></p>
<h3 id="Icon-Based-Visualization-Techniques"><a href="#Icon-Based-Visualization-Techniques" class="headerlink" title="Icon-Based Visualization Techniques"></a>Icon-Based Visualization Techniques</h3><blockquote>
<p>Icon-based visualization techniques use small icons to represent multidimensional data values</p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/42334717/74634337-fa101380-51a6-11ea-8ba2-13030ecf6be7.png" alt="Icon-Based Visualization Techniques"></p>
<h3 id="Hierarchical-Visualization-Techniques"><a href="#Hierarchical-Visualization-Techniques" class="headerlink" title="Hierarchical Visualization Techniques"></a>Hierarchical Visualization Techniques</h3><blockquote>
<p>Hierarchical Visualization Techniques partition all dimensions into subsets</p>
</blockquote>
<h2 id="Measuring-Data-Similarity-and-Dissimilarity"><a href="#Measuring-Data-Similarity-and-Dissimilarity" class="headerlink" title="Measuring Data Similarity and Dissimilarity"></a>Measuring Data Similarity and Dissimilarity</h2><blockquote>
<p>In data mining applications, such as clustering, outlier analysis, and nearest-neighbor classification, we need ways to assess how alike or unalike objects are in comparison to one another</p>
</blockquote>
<h3 id="Data-Matrix-versus-Dissimilarity-Matrix"><a href="#Data-Matrix-versus-Dissimilarity-Matrix" class="headerlink" title="Data Matrix versus Dissimilarity Matrix"></a>Data Matrix versus Dissimilarity Matrix</h3><ul>
<li>Data matrix(or $object-by-attribute structure$)<ul>
<li>This structure stores the $n$ data objects in the form of a relational table</li>
<li>$n-by-p$ matrix</li>
<li>$n\ objects\ \times\ p\ attributes$</li>
</ul>
</li>
</ul>
<p>$$<br>\begin{bmatrix}{}<br>x_{11} &amp; \ldots &amp; x_{1f} &amp; \ldots &amp; x_{1p} \\<br>\ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots \\<br>x_{i1} &amp; \ldots &amp; x_{if} &amp; \ldots &amp; x_{ip} \\<br>\ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots \\<br>x_{n1} &amp; \ldots &amp; x_{nf} &amp; \ldots &amp; x_{np} \\<br>\end{bmatrix}<br>$$</p>
<ul>
<li>Dissimilarity matrix(or $object-by-object structure$)<ul>
<li>This structure stores a collection of proximities that are available for all pairs of $n$ objects</li>
<li>$n-by-n$ table</li>
<li>$d(i,j)$ : The measured dissimilarity or difference between objects $i$ and $j$</li>
<li>In general, $d(i,j)$ is a non-negative number that is close to 0 when objects $i$ and $j$ are highly similar or near each other, and becomes larger the more they differ</li>
<li>$d(i,j)=d(j,i)$</li>
</ul>
</li>
</ul>
<p>$$<br>\begin{bmatrix}{}<br>0 \\<br>d(2,1) &amp; 0 \\<br>d(3,1) &amp; d(3,2) &amp; 0 \\<br>\vdots &amp; \vdots &amp; \vdots \\<br>d(n,1) &amp; d(n,2) &amp; \ldots &amp; \ldots &amp; 0 \\<br>\end{bmatrix}<br>$$</p>
<ul>
<li>The similarity between objects $i$ and $j$</li>
</ul>
<p>$$sim(i,j)=1-d(i,j)$$</p>
<ul>
<li>Data matrix : Two-mode matrix(Two entities or things, namely rows(for objects) and columns(for attributes))</li>
<li>Dissimilarity matrix : One-mode matrix(One kind of entity(dissimilarities))</li>
</ul>
<h3 id="Proximity-Measures-for-Nominal-Attribute"><a href="#Proximity-Measures-for-Nominal-Attribute" class="headerlink" title="Proximity Measures for Nominal Attribute"></a>Proximity Measures for Nominal Attribute</h3><ul>
<li>The dissimilarity between two objects $i$ and $j$<ul>
<li>$m$ : The number of matches</li>
<li>$p$ : The total number of attributes describing the objects</li>
<li>Weights can be assigned to increase the effect of $m$ or to assign greater weight to the matches in attributes having a larger number of states</li>
</ul>
</li>
</ul>
<p>$$d(i,j)=\frac{p-m}{p}$$</p>
<ul>
<li>The similarity<br>$$sim(i,j)=1-d(i,j)=\frac{m}{p}$$</li>
</ul>
<h3 id="Proximity-Measures-for-Binary-Attributes"><a href="#Proximity-Measures-for-Binary-Attributes" class="headerlink" title="Proximity Measures for Binary Attributes"></a>Proximity Measures for Binary Attributes</h3><p><img src="https://user-images.githubusercontent.com/42334717/74701775-3a28d200-524b-11ea-8608-41c177e88e74.png" alt="Binary Attributes Table"></p>
<p>$$p=q+r+s+t$$</p>
<ul>
<li><p>Symmetric binary dissimilarity<br>$$d(i,j)=\frac{r+s}{q+r+s+t}$$</p>
</li>
<li><p>Asymmetric binary dissimilarity</p>
<ul>
<li>$t$ is considered unimportant and is thus ignored in the following computation<br>$$d(i,j)=\frac{r+s}{q+r+s}$$</li>
</ul>
</li>
<li><p>Asymmetric binary similarity<br>$$sim(i,j)=\frac{q}{q+r+s}=1-d(i,j)$$</p>
</li>
</ul>
<h3 id="Dissimilarity-of-Numeric-Data-Minkowski-Distance"><a href="#Dissimilarity-of-Numeric-Data-Minkowski-Distance" class="headerlink" title="Dissimilarity of Numeric Data : Minkowski Distance"></a>Dissimilarity of Numeric Data : Minkowski Distance</h3><ul>
<li><p>Euclidean distance<br>$$d(i,j)=\sqrt{(x_{i1}-x_{j1})^2+(x_{i2}-x_{j2})^2+…+(x_{ip}-x_{jp})^2}$$</p>
</li>
<li><p>Mangattan(or city block) distance<br>$$d(i,j)=|x_{i1}-x_{j1}|+|x_{i2}-x_{j2}|+…+|x_{ip}-x_{jp}|$$</p>
</li>
</ul>
<ul>
<li>Both the Euclidean and the Manhattan distance satisfy the following mathematical properties<ul>
<li>Non-negativity : $d(i,j)\geq0$ : Distance is a non-negative number</li>
<li>Identity of indiscernibles : $d(i,i)=0$ : The distance of an object to itself is 0</li>
<li>Symmertry : $d(i,j)=d(j,i)$ : Distance is a symmetric function</li>
<li>Triangle inequality : $d(i,j)\leq d(i,k)+d(k,j)$ : Going directly from object $i$ to object $j$ in space is no more than making a detour over any other object $k$</li>
</ul>
</li>
</ul>
<ul>
<li>The supremum distance($L_{max},\ L_{\infty}\ norm,\ Chebyshev\ distance$)<ul>
<li>A generalization of the Minkowski distance for $h\to \infty$<br>$$d(i,j)=\lim_{h\to \infty}(\sum_{f=1}^p|x_{if}-x_{jf}|^h)^{\frac{1}{h}}=\max_f^p|x_{if}-x_{jf}|$$</li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/42334717/74702739-39de0600-524e-11ea-96a9-7d57e679845a.png" alt="Distance"></p>
<h3 id="Proximity-Measures-for-Ordinal-Attributes"><a href="#Proximity-Measures-for-Ordinal-Attributes" class="headerlink" title="Proximity Measures for Ordinal Attributes"></a>Proximity Measures for Ordinal Attributes</h3><ul>
<li>$M$ : Represent the number of possible states that an ordinal attribute can have</li>
<li>$f$ : An attribute from a set of ordinal attributes describing $n$ objects</li>
</ul>
<ol>
<li>The value of $f$ for the $i$th object is $x_{if}$, and $f$ has $M_f$ ordered states, representing the ranking $1,…,M_f$. Replace each $x_{if}$ by its corresponding rank, $r_{if}\in{1,…,M_f}$</li>
<li>Since each ordinal attribute can have a different number of sstates, it is often necessary to map the range of each attribute onto $[0.0,\ 1.0]$ so that each attribute has equal weight. We perform such data normalization by replacing the rank $r_{if}$ of the $i$th object in the $f$th attribute by<br>$$z_{if}=\frac{r_{if}-1}{M_f-1}$$</li>
<li>Dissimilarity can then be computed using any of the distance measures, using $z_{if}$ to represent the $f$ value for the $i$th object.</li>
</ol>
<h3 id="Dissimilarity-for-Attributes-of-Mixed-Types"><a href="#Dissimilarity-for-Attributes-of-Mixed-Types" class="headerlink" title="Dissimilarity for Attributes of Mixed Types"></a>Dissimilarity for Attributes of Mixed Types</h3><ul>
<li>The dissimilarity $d(i,j)$ between objects $i$ and $j$<ul>
<li>The data set contains $p$ attributes of mixed type</li>
<li>The indicator $\delta_{ij}^{(f)}$<ul>
<li>$\delta_{ij}^{(f)}=0$<ol>
<li>$x_{if}$ or $x_{jf}$ is missing</li>
<li>$x_{if}=x_{jf}=0$ and attribute $f$ is asymmetric binary</li>
</ol>
</li>
<li>$\delta_{ij}^{(f)}=1$<ul>
<li>The contribution of attribute $f$ to the dissimilarity between $i$ and $j$(i.e., $d_{ij}^{(f)}$) is computed dependent on its type:<ol>
<li>If $f$ is numeric : $d_{ij}^{(f)}=\frac{|x_{if}-x_{jf}|}{\max_hx_{hf}-\min_hx_{hf}}$, where $h$ runs over all nonmissing objects for attribute $f$</li>
<li>If $f$ is nominal or binary : $d_{ij}^{(f)}=0$ if $x_{if}=x_{jf}$; otherwise, $d_{if}^{(f)}=1$</li>
<li>If $f$ is ordinal : compute the ranks $r_{if}$ and $z_{if}=\frac{r_{if}-1}{M_f-1}$, and treat $z_{if}$ as numeric<br>$$d(i,j)=\frac{\sum_{f=1}^p \delta_{ij}^{(f)}d_{ij}^{(f)}}{\sum_{f=1}^p \delta_{ij}^{(f)}}$$</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Cosine-Similarity"><a href="#Cosine-Similarity" class="headerlink" title="Cosine Similarity"></a>Cosine Similarity</h3><p>Term-frequency vector : Each document is an object represented(Typically very long and sparse)</p>
<ul>
<li><p>Similarity function</p>
<ul>
<li>Measure of similarity that can be used to compare documents or, say, give a ranking of documents with respect to a given vector of query words</li>
<li>$\boldsymbol{x},\ \boldsymbol{y}$ : Two vectors for comparision</li>
<li>$||\boldsymbol{x}||$ : Euclidean norm of vector $\boldsymbol{x}=(x_1,x_2,…,x_p)$</li>
<li>$||\boldsymbol{y}||$ : Euclidean norm of vector $\boldsymbol{y}=(y_1,y_2,…,y_p)$</li>
<li>A cosine value of 0 means that the two vectors are at 90 degrees to each other (orthognal) and have no match</li>
<li>The closer the cosine value of 1, the smaller the angle and the greater the match between vectors<br>$$sim(\boldsymbol{x},\boldsymbol{y})=\frac{\boldsymbol{x}\cdot \boldsymbol{y}}{||\boldsymbol{x}||||\boldsymbol{y}||}$$</li>
</ul>
</li>
<li><p>Tanimoto coefficient(or Tanimoto distance)</p>
<ul>
<li>When attributes are binary-valued, the cosine similarity function can be interpreted in terms of shared features or attributes</li>
<li>The ratio of the number of attributes shared by $\boldsymbol{x}$ and $\boldsymbol{y}$ to the number of attributes possessed by $\boldsymbol{x}$ or $\boldsymbol{y}$<br>$$sim(\boldsymbol{x},\boldsymbol{y})=\frac{\boldsymbol{x}\cdot \boldsymbol{y}}{\boldsymbol{x}\cdot \boldsymbol{x}+\boldsymbol{y}\cdot \boldsymbol{y}-\boldsymbol{x}\cdot \boldsymbol{y}}$$</li>
</ul>
</li>
</ul>
<hr>
<h1 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h1><ol>
<li>Data Cleaning</li>
<li>Data Integration</li>
<li>Data Reduction</li>
<li>Data Transformation</li>
</ol>
<p><img src="https://user-images.githubusercontent.com/42334717/89777041-f487fa80-db45-11ea-9dc4-f9a644fb68b9.png" alt="Data Processing"></p>
<ul>
<li>데이터 품질을 결정하는 요소<ul>
<li>정확성</li>
<li>완전성</li>
<li>일관성</li>
<li>적시성</li>
<li>신뢰성</li>
<li>해석 가능성</li>
</ul>
</li>
</ul>
<h2 id="Data-Cleaning"><a href="#Data-Cleaning" class="headerlink" title="Data Cleaning"></a>Data Cleaning</h2><h3 id="Missing-Values"><a href="#Missing-Values" class="headerlink" title="Missing Values"></a>Missing Values</h3><ol>
<li>Ignore the tuple</li>
<li>Fill in the missing value manually</li>
<li>Use a global constant to fill in the missing value</li>
<li>Use a measure of central tendency for the attribute to fill in the missing value</li>
<li>Use the attribute mean or median for all samples belonging to the same class as the given tuple</li>
<li>Use the most probable value to fill in the missing value</li>
</ol>
<h3 id="Noisy-Data"><a href="#Noisy-Data" class="headerlink" title="Noisy Data"></a>Noisy Data</h3><blockquote>
<p>Noise is a random error or variance in a measured variable</p>
</blockquote>
<blockquote>
<p>Binning : Binning methods smooth a sorted data value by consulting its “neighbor-hood” that is, the values around it.</p>
</blockquote>
<ul>
<li>Smoothing by bin means</li>
<li>Smoothing by bin medians</li>
<li>Smoothing by bin boundaries</li>
<li>Regression</li>
<li>Outlier analysis</li>
</ul>
<h3 id="Data-Cleaning-as-a-Process"><a href="#Data-Cleaning-as-a-Process" class="headerlink" title="Data Cleaning as a Process"></a>Data Cleaning as a Process</h3><blockquote>
<p>As we discover more about the data, it is important to keep updating the metadata to reflect this knowledge</p>
</blockquote>
<h2 id="Data-Integration"><a href="#Data-Integration" class="headerlink" title="Data Integration"></a>Data Integration</h2><blockquote>
<p>Data mining often requires data integration - the merging of data from multiple data stores</p>
</blockquote>
<h3 id="Redundancy-and-Correlation-Analysis"><a href="#Redundancy-and-Correlation-Analysis" class="headerlink" title="Redundancy and Correlation Analysis"></a>Redundancy and Correlation Analysis</h3><blockquote>
<p>Some redundancies can be detected by correlation analysis</p>
</blockquote>
<h4 id="chi-2-Correlation-Test-for-Nominal-Data"><a href="#chi-2-Correlation-Test-for-Nominal-Data" class="headerlink" title="$\chi^2$ Correlation Test for Nominal Data"></a>$\chi^2$ Correlation Test for Nominal Data</h4><blockquote>
<p>For nominal data, a correlation relationship between two attributes, A and B, can be discovered by a $\chi^2$(chi-square) test</p>
</blockquote>
<ul>
<li>The $\chi^2$ value(also known as the $Pearson\ \chi^2\ statistic$)<ul>
<li>A has $c$ distinct values, namely $a_1, a_2, …, a_c$</li>
<li>B has $r$ distinct values, namely $b_1, b_2, …, b_r$</li>
<li>The data tuples described by A and B can be shown as  a contingency table, with the $c$ values of A making up the columns and the $r$ values of B making up the rows</li>
<li>Let $(A_i,B_j)$ denote the joint event that attribute A takes on value $a_i$ and attribute B takes on value $b_j$, that is, where $(A=a_i,B=b_j)$</li>
</ul>
</li>
</ul>
<p>$$\chi^2=\sum_{i=1}^c\sum_{j=1}^r\frac{(o_{ij}-e_{ij})^2}{e_{ij}}$$</p>
<ul>
<li>$e_{ij}$ : The expected frequency of $(A_i,B_j)$<ul>
<li>$o_{ij}$ : The observed frequency(i.e., actual count) of the joint event $(A_i,B_j)$</li>
<li>n : The number of data tuples</li>
<li>$count(A=a_i)$ : The number of tuples having value $a_i$ for A</li>
<li>$count(B=b_i)$ : The number of tuples having value $b_i$ for B</li>
</ul>
</li>
</ul>
<p>$$e_{ij}=\frac{count(A=a_i)\times count(B=b_j)}{n}$$</p>
<ul>
<li>The $\chi^2$ statistics tests the hypothesis that A and B are independent, that is, there is no correlation between them</li>
<li>The test is based on a significance level, with $(r-1)\times (c-1)$ degrees of freedom</li>
<li>If the hypothesis can be rejected, then we say that A and B are statistically correlated</li>
</ul>
<h4 id="Correlation-Coefficient-for-Numeric-Data"><a href="#Correlation-Coefficient-for-Numeric-Data" class="headerlink" title="Correlation Coefficient for Numeric Data"></a>Correlation Coefficient for Numeric Data</h4><ul>
<li>The correlation coefficient(Pearson’s product moment coefficient)<ul>
<li>$n$ : The number of tuples</li>
<li>$a_i$ : The value of A in tuple $i$</li>
<li>$b_i$ : The value of B in tuple $j$</li>
<li>$\bar A$ : The mean value of A</li>
<li>$\bar B$ : The mean value of B</li>
<li>$\sigma_A$ : The standard deviation of A</li>
<li>$\sigma_B$ : The standard deviation of B</li>
<li>$\sum(a_ib_i)$ : The sum of the AB cross-product</li>
<li>$-1\leq r_{A,B}\leq+1$</li>
<li>If $r_{A,B}$ is greater than 0, then A and B are positively correlated</li>
<li>Hence, a higher value may indicate that A (or B) may be removed as a redundancy</li>
<li>If the resulting value is equal to 0, then A and B are independent and there is no correlation between them</li>
<li>If the resulting value is less than 0, then A and B are negatively correlated, where the values of one attribute increase as the values of the other attribute decrease</li>
<li>Scatter plots can also be used to view correlations between attributes</li>
</ul>
</li>
</ul>
<p>$$r_{A,B}=\frac{\sum_{i=1}^n(a_i-\bar A)(b_i-\bar B)}{n\sigma_A\sigma_B}=\frac{\sum_{i=1}^n(a_ib_i)-n\bar A\bar B}{n\sigma_A\sigma_B}$$</p>
<h4 id="Covariance-of-Numeric-Data"><a href="#Covariance-of-Numeric-Data" class="headerlink" title="Covariance of Numeric Data"></a>Covariance of Numeric Data</h4><ul>
<li>The mean values of A and B, respectively, are also known as the expected values on A and B</li>
</ul>
<p>$$E(A)=\bar A=\sum_{i=1}^na_i$$</p>
<p>$$E(B)=\bar B=\sum_{i=1}^nb_i$$</p>
<ul>
<li>Covariance<ul>
<li>In probability theory and statistics, correlation and covariance are two similar measures for assessing how much two attributes change together</li>
<li>For two attributes A and B that tend to change together, if A is larger than $\bar A$, then B is likely to be larger than $\bar B$</li>
<li>Therefore, the covariance between A and B is positive</li>
<li>On the other hand, if one of the attributes tends to be above its expected value when the other attribute is below its expected value, then the covariance of A and B is negative</li>
<li>If A and B are independent(i.e., they do not have correlation), then $E(A\cdot B)=E(A)\cdot E(B)$</li>
<li>Therefore, the covariance is $Cov(A,B)=E(A\cdot B)-\bar A\bar B=E(A)\cdot E(B)-\bar A\bar B=0$</li>
<li>However, the converse is not true</li>
<li>Some pairs of random variables(attributes) may have a covariance of 0 but are not independent</li>
</ul>
</li>
</ul>
<p>$$<br>Cov(A,B)=E((A-\bar A)(B-\bar B))=\frac{\sum_{i=1}^n(a_i-\bar A)(b_i-\bar B)}{n}<br>$$<br>$$<br>Cov(A,B)=E(A\cdot B)-\bar A\bar B<br>$$</p>
<ul>
<li>$r_{A,B}$(Correlation coefficient)<ul>
<li>for covariance</li>
</ul>
</li>
</ul>
<p>$$<br>r_{A,B}=\frac{Cov(A,B)}{\sigma_A\sigma_B}<br>$$</p>
<ul>
<li>Standard deviations of A and B, respectively<ul>
<li>$\sigma_A$</li>
<li>$\sigma_B$</li>
</ul>
</li>
</ul>
<h3 id="Tuple-Duplication"><a href="#Tuple-Duplication" class="headerlink" title="Tuple Duplication"></a>Tuple Duplication</h3><blockquote>
<p>In addition to detecting redundancies between attributes, duplication should also be detected at the tuple level</p>
</blockquote>
<ul>
<li>The use of denormalized tables(often done to improve performance by avoiding joins) is another source of data redundancy</li>
<li>Inconsistencies often arise between various duplicates, due to inaccurate data entry or updating some but not all data occurences</li>
</ul>
<h3 id="Data-Value-Conflict-Detection-and-Resolution"><a href="#Data-Value-Conflict-Detection-and-Resolution" class="headerlink" title="Data Value Conflict Detection and Resolution"></a>Data Value Conflict Detection and Resolution</h3><blockquote>
<p>Data integration also involves the detection and resolution of data value conflicts</p>
</blockquote>
<ul>
<li>Differences in representation</li>
<li>Scaling</li>
<li>Encoding</li>
</ul>
<h2 id="Data-Reduction"><a href="#Data-Reduction" class="headerlink" title="Data Reduction"></a>Data Reduction</h2><blockquote>
<p>Data reduction techniques can be applied to obtain a reduced representation of the data set that is much smaller in volume, yet closely maintains the integrity of the original data</p>
</blockquote>
<h3 id="Overview-of-Data-Reduction-Strategies"><a href="#Overview-of-Data-Reduction-Strategies" class="headerlink" title="Overview of Data Reduction Strategies"></a>Overview of Data Reduction Strategies</h3><ul>
<li>Dimensionality reduction<ul>
<li>The process of reducing the number of random variables or attributes under consideration</li>
</ul>
</li>
<li>Numerosity reduction<ul>
<li>The techniques replace the original data volume by alternative, smaller forms of data representation</li>
</ul>
</li>
<li>Data compression<ul>
<li>Transformations are applied so as to obtain a reduced or “compressed” representation of the original data</li>
</ul>
</li>
</ul>
<p><strong>The computational time spent on data reduction should not out weigh or “erase” the time saved by mining on a reduced data set size</strong></p>
<h3 id="Wavelet-Transform"><a href="#Wavelet-Transform" class="headerlink" title="Wavelet Transform"></a>Wavelet Transform</h3><blockquote>
<p>The discrete wavelet transform(DWT) is a linear signal processing technique that, when applied to a data vector <strong>X</strong>, transforms it to a numerically different vector, <strong>X’</strong>, of wavelet coefficients</p>
</blockquote>
<ul>
<li>Consider each tuple as an $n$-dimensional data vector<ul>
<li><strong>$X$</strong>$=(x_1,x_2,…,x_n)$</li>
<li>Depicting $n$ measurements made on the tuple from $n$ database attributes</li>
</ul>
</li>
<li>The DWT is closely related to the discrete Fourier transform(DFT)<ul>
<li>DFT : A signal processing technique involving sines and cosines</li>
</ul>
</li>
</ul>
<h3 id="Principal-Components-Analysis-PCA"><a href="#Principal-Components-Analysis-PCA" class="headerlink" title="Principal Components Analysis(PCA)"></a>Principal Components Analysis(PCA)</h3><blockquote>
<p>데이터를 표현하는데 가장 잘 사용할 수 있는 직교 벡터 분석</p>
</blockquote>
<ul>
<li>정렬된 속성과 정렬되지 않은 속성에 적용할 수 있음</li>
<li>희소 데이터와 치우친 데이터를 처리할 수 있음</li>
<li>2차원 이상의 다차원 데이터는 문제를 2차원으로 줄여 처리</li>
<li>웨이블릿 변환과 비교 시 PCA는 희소 데이터를 처리하는데 더 나은 경향이 있는 반면, 웨이블릿 변환은 고차원 데이터에 더 적합</li>
</ul>
<h3 id="Attribute-Subset-Selection"><a href="#Attribute-Subset-Selection" class="headerlink" title="Attribute Subset Selection"></a>Attribute Subset Selection</h3><blockquote>
<p>관련이 없거나 중복된 속성(또는 차원)을 제거하여 데이터의 크기를 줄임</p>
</blockquote>
<ul>
<li>데이터 클래스의 결과 확률 분포가 모든 속성을 사용하여 얻은 원래 분포에 최대한 가깝도록 속성의 최소 집합을 찾음</li>
<li>검색된 패턴에 나타나는 속성의 수를 줄여 패턴을 이해하기 쉽게 만듦</li>
</ul>
<h3 id="Regression-and-Log-Linear-Models-Parametric-Data-Reduction"><a href="#Regression-and-Log-Linear-Models-Parametric-Data-Reduction" class="headerlink" title="Regression and Log-Linear Models : Parametric Data Reduction"></a>Regression and Log-Linear Models : Parametric Data Reduction</h3><blockquote>
<p>Regression and log-linear models can be used to approximate the give data</p>
</blockquote>
<p>$$<br>y=\omega x+b<br>$$</p>
<ul>
<li>$y$ : Respoonse variable</li>
<li>$x$ : Predictor variable</li>
<li>$\omega ,b$ : Regression coefficients</li>
</ul>

    </div>

    
    
    
      
  <div class="popular-posts-header">Related posts</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/classification/" rel="bookmark">Classification</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/development-of-a-obstructive-sleep-apnea-diagnosis-algorithm-using-hrv/" rel="bookmark">Development of a Obstructive Sleep Apnea Diagnosis Algorithm Using HRV</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/diagnosis-systems-for-ball-bearing-cage-defects-using-fisher-discriminant-ratio/" rel="bookmark">Diagnosis Systems for Ball Bearing Cage Defects using Fisher Discriminant Ratio</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/diagnosis-systems-with-smart-data-for-3d-printer-introduction/" rel="bookmark">Diagnosis Systems with Smart Data for 3D Printer(Introduction)</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/diagnosis-systems-with-smart-data-for-3d-printer/" rel="bookmark">Diagnosis Systems with Smart Data for 3D Printer</a></div>
    </li>
  </ul>


    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Zerohertz
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://zerohertz.github.io/data-mining/" title="Data Mining">https://zerohertz.github.io/data-mining/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/machine-learning/" rel="tag"><i class="fa fa-tag"></i> Machine Learning</a>
              <a href="/tags/signal-processing/" rel="tag"><i class="fa fa-tag"></i> Signal Processing</a>
              <a href="/tags/dnn/" rel="tag"><i class="fa fa-tag"></i> DNN</a>
              <a href="/tags/statistics/" rel="tag"><i class="fa fa-tag"></i> Statistics</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/a-phm-approach-to-additive-manufacturing-equipment-health-monitoring-fault-diagnosis-and-quality-control/" rel="prev" title="A PHM Approach to Additive Manufacturing Equipment Health Monitoring, Fault Diagnosis, and Quality Control">
                  <i class="fa fa-chevron-left"></i> A PHM Approach to Additive Manufacturing Equipment Health Monitoring, Fault Diagnosis, and Quality Control
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/domain-knowledge-based-data-preprocessing-technology-for-industrial-applications-of-deep-learning/" rel="next" title="Domain Knowledge Based Data Preprocessing Technology for Industrial Applications of Deep Learning">
                  Domain Knowledge Based Data Preprocessing Technology for Industrial Applications of Deep Learning <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
  
  
  



      
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-theater-masks"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zerohertz</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Symbols count total: </span>
    <span title="Symbols count total">558k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">8:27</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9waXNjZXMv">NexT.Pisces</span>
  </div>

    </div>
  </footer>

  
  <script size="150" alpha="0.8" zindex="-2" src="//cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  




  <script src="/js/local-search.js"></script>















  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.0/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-zerohertz-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://zerohertz.github.io/data-mining/";
    this.page.identifier = "data-mining/";
    this.page.title = "Data Mining";
    };
  NexT.utils.loadComments('#disqus_thread', () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://https-zerohertz-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
